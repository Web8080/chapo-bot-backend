 README.md for Chapo Bot 
# ğŸ¤– Chapo Bot - Voice-Controlled Home Assistant

Chapo is an intelligent, voice-controlled home assistant designed for real-time interaction, environmental awareness, and personalized response generation. Built with Whisper, GPT, Wit.ai, and modular intent engines, Chapo aims to become a fully autonomous and emotionally-aware smart companion.

---

## ğŸ“¦ Features

### âœ… Core Features (Implemented)
- ğŸ™ï¸ Real-time voice recognition with Whisper
- ğŸ§  Intent detection using Wit.ai and HuggingFace
- ğŸ¤– GPT fallback for open-ended queries
- ğŸ˜Š Emotion detection via facial expression analysis
- ğŸ“Š MongoDB logging for all user interactions and metrics
- ğŸ›ï¸ Shopping list handler with persistent JSON storage

### ğŸ”§ Planned Integrations
- ğŸ  IoT device control via Home Assistant
- ğŸ“… Google Calendar API for reminders & events
- ğŸ—ºï¸ Google Maps API for location-based queries
- ğŸµ Spotify integration (currently broken)
- ğŸ‘ï¸ YOLOv8 for real-time object detection
- ğŸ“ˆ Streamlit dashboard for real-time insights

---

## ğŸ§  System Architecture

```mermaid
graph TD
    UserVoice[ğŸ¤ User Voice Input]
    Whisper[ğŸ§  Whisper STT]
    Wit[ğŸ” Wit.ai Intent Detection]
    GPT[ğŸ¤– GPT Fallback]
    Router[ğŸ› ï¸ Intent Router]
    Engines[âš™ï¸ Chapo Engines]
    DB[ğŸ—‚ï¸ MongoDB Logs]
    Camera[ğŸ“¸ Real-time Vision]
    Emotion[ğŸ˜Š Emotion Detector]

    UserVoice --> Whisper
    Whisper --> Wit
    Wit --> Router
    Router --> Engines
    Router --> GPT
    Engines --> DB
    Camera --> Emotion
    Emotion --> Router

ğŸ§° Tech Stack
Category	Technology
Language	Python 3.10+
Backend	FastAPI
NLP	Whisper, Wit.ai, OpenAI GPT, HuggingFace
Voice I/O	PyAudio, gTTS, pyttsx3
Data Storage	MongoDB, JSON
Vision	OpenCV, YOLOv8, ONNX
Dashboard (planned)	Streamlit, Dash, Flask
Dev Tools	dotenv, logging, asyncio
ğŸ“‚ Folder Structure
backend/
â”œâ”€â”€ app.py / main.py                  # Entry points for running the FastAPI app (if web/API interface is enabled)
â”œâ”€â”€ test_voice.py                     # ğŸ™ï¸ Main voice loop: handles input, transcription, intent detection, response
â”œâ”€â”€ realtime_voice.py                 # Handles streaming or continuous voice capture
â”œâ”€â”€ response_generator.py             # ğŸ§  Generates dynamic responses using multi-turn logic or GPT fallback
â”œâ”€â”€ emotion_detector.py               # ğŸ˜Š Detects user emotion from speech or facial cues
â”œâ”€â”€ realtime_emotion_detect.py        # Real-time webcam-based emotion recognition using FER
â”œâ”€â”€ realtime_object_detect.py         # Real-time object detection using YOLOv8 + OpenCV
â”œâ”€â”€ spotify_handler.py                # Spotify helper functions (auth, playback), used in integration
â”œâ”€â”€ feedback.py                       # Collects and logs user feedback on responses
â”œâ”€â”€ multi_turn_manager.py             # Tracks context for multi-turn conversations
â”œâ”€â”€ evaluate_model.py / eval_metrics.py # ğŸ“Š Evaluate accuracy of intent predictions (Wit.ai / HuggingFace)
â”œâ”€â”€ db/mongo.py                            # Connects to MongoDB, stores logs & evaluation metrics
â”œâ”€â”€ download_yolo_files.py            # Downloads YOLO model weights and files
â”œâ”€â”€ requirements.txt                  # List of Python dependencies

# âœ… NLP / Wit.ai Integration
â”œâ”€â”€ wit_bulk_upload.py                # Uploads multiple intents/utterances to Wit.ai
â”œâ”€â”€ wit_upload_csv_style.py           # Uploads utterances from CSV-formatted structure
â”œâ”€â”€ wit.ai_upload_new.py              # Alternative Wit.ai uploader script

# ğŸ“ Routers
â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ voice.py                      # Handles API routes for voice commands
â”‚   â”œâ”€â”€ text.py                       # Handles routes for text queries
â”‚   â”œâ”€â”€ interactions.py               # Route logic for interactions with users or modules

# ğŸ§  Intelligence Engines (modular)
â”œâ”€â”€ chapo_engines/
â”‚   â”œâ”€â”€ core_conversation_engine.py   # Central dispatch logic to other engines
â”‚   â”œâ”€â”€ reminder_engine.py            # Reminders, alarms, scheduling
â”‚   â”œâ”€â”€ shopping_list_engine.py       # JSON-based shopping list manager
â”‚   â”œâ”€â”€ fitness_engine.py             # Fitness prompts, suggestions, logs
â”‚   â”œâ”€â”€ knowledge_engine.py           # Trivia, facts, and question answering
â”‚   â”œâ”€â”€ wellness_engine.py            # Mood check-ins, journaling, meditation
â”‚   â”œâ”€â”€ gp_engine.py                  # Health data interaction engine
â”‚   â”œâ”€â”€ sleep_engine.py               # Sleep routines or logging
â”‚   â”œâ”€â”€ entertainment_engine.py       # Music, games, storytelling
â”‚   â”œâ”€â”€ security_engine.py            # Home surveillance or threat detection
â”‚   â”œâ”€â”€ tv_engine.py                  # Smart TV control or suggestions
â”‚   â””â”€â”€ ... (20+ total engines)       # Each handling a narrow, modular domain

# ğŸ§¾ JSON Data Logs & Training Files
â”œâ”€â”€ session_logs.json                # Stores all conversation sessions
â”œâ”€â”€ feedback_logs.json               # Records user thumbs-up/down feedback
â”œâ”€â”€ shopping_list.json               # ğŸ›’ Persistent local shopping list store
â”œâ”€â”€ trivia_questions.json            # Dataset of trivia questions
â”œâ”€â”€ utterance_to_response.json       # Maps common utterances to canned replies
â”œâ”€â”€ intent_to_utterances.json        # Maps intents to example phrases for training
â”œâ”€â”€ gp_reports.json / training.json  # Medical report storage or dummy data
â”œâ”€â”€ medication_schedule.json         # Medication reminders and logs
â”œâ”€â”€ witai_utterances_formatted.json  # Formatted data for Wit.ai bulk training
|---- alarms.json

# âš™ï¸ Model Weights
â”œâ”€â”€ yolov8n.pt                       # YOLOv8 object detection model
â”œâ”€â”€ yolov5su.pt                      # Alternative or older YOLOv5 model
â”œâ”€â”€ imagenet_classes.txt             # Object labels for model predictions

# ğŸ”ˆ Audio & Media
â”œâ”€â”€ test.wav                         # Example user input
â”œâ”€â”€ voice_input.wav                  # Temporary raw recording
â”œâ”€â”€ cat.png                          # Test image for visual functions

# ğŸ”¬ Evaluation & Logging
â”œâ”€â”€ eval_log.csv / eval_log_new.csv # Logs of model evaluation metrics

ğŸš€ Getting Started
ğŸ”§ Installation
# Clone the repository
git clone https://github.com/yourusername/chapo-bot.git
cd chapo-bot/backend

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate

# Install dependencies
pip install -r requirements.txt

ğŸ”‘ Environment Variables
Create a .env file in the backend/ directory with the following:
MONGODB_URI=your_mongodb_connection_string
WIT_AI_TOKEN=your_wit_ai_token
OPENAI_API_KEY=your_openai_key

ğŸ—£ï¸ Usage
python test_voice.py
Speak to Chapo and receive intelligent, emotional, or GPT-based responses with intent-aware functionality.

ğŸ“ˆ Roadmap
* Add Home Assistant integration
* Google Calendar support for reminders/events
* Reactivate and stabilize Spotify module
* Improve fallback routing from GPT â†’ core logic
* Add persistent JSON storage for tasks/alarms
* Create a visual dashboard using Streamlit/Dash
* Enhance object recognition via camera input

ğŸ§  Challenges Faced
* â— Asynchronous race conditions with shopping list updates
* â— Overlapping intents in multi-action commands (e.g., â€œAdd milk and remind me tomorrowâ€)
* â— Spotify authentication & token refresh bugs
* â— GPT fallback generating good responses but not triggering actions
* â— Lack of visual UI made debugging interaction flows slow
* â— Natural language date/time parsing for reminders was unreliable

ğŸ§ª Testing
To evaluate intent prediction accuracy:
python evaluate_model.py
Check eval_metrics.py for metrics such as precision, recall, and F1-score.

ğŸ§™ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what youâ€™d like to change.

ğŸªª License
MIT Â© 2025 â€” Islington Robotica Team

---
